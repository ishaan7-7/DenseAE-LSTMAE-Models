{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_models_simple.py\n",
    "from pathlib import Path\n",
    "import json, joblib, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "import mlflow, mlflow.pyfunc\n",
    "\n",
    "MLFLOW_URI = \"http://127.0.0.1:5000\"\n",
    "MODELS_DIR = Path(\"Models\")\n",
    "ART_DIR    = Path(\"artifacts_tf\")\n",
    "SEQ_LEN = 30\n",
    "\n",
    "# LSTM hyperparams used during training (match your grid)\n",
    "LSTM_CFG = {\n",
    "    \"artifact_1\": dict(hidden=64,  latent=16, layers=1),\n",
    "    \"artifact_2\": dict(hidden=96,  latent=24, layers=1),\n",
    "    \"artifact_3\": dict(hidden=80,  latent=20, layers=1),\n",
    "    \"artifact_4\": dict(hidden=64,  latent=16, layers=2),\n",
    "    \"artifact_5\": dict(hidden=72,  latent=18, layers=1),\n",
    "}\n",
    "\n",
    "class DenseAE(nn.Module):\n",
    "    def __init__(self, in_dim=60):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(in_dim,40),nn.ReLU(),nn.Linear(40,20),nn.ReLU(),nn.Linear(20,10),nn.ReLU())\n",
    "        self.dec = nn.Sequential(nn.Linear(10,20),nn.ReLU(),nn.Linear(20,40),nn.ReLU(),nn.Linear(40,in_dim))\n",
    "    def forward(self,x): return self.dec(self.enc(x))\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self,input_dim=60,hidden_dim=64,latent_dim=16,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder=nn.LSTM(input_dim,hidden_dim,num_layers=num_layers,batch_first=True)\n",
    "        self.to_latent=nn.Linear(hidden_dim,latent_dim); self.from_latent=nn.Linear(latent_dim,hidden_dim)\n",
    "        self.decoder=nn.LSTM(input_dim,hidden_dim,num_layers=num_layers,batch_first=True); self.out=nn.Linear(hidden_dim,input_dim)\n",
    "        self.num_layers=num_layers; self.hidden_dim=hidden_dim\n",
    "    def forward(self,x):\n",
    "        enc,_=self.encoder(x); h=enc[:,-1,:]; z=self.to_latent(h); base=self.from_latent(z)\n",
    "        h0=base.unsqueeze(0).repeat(self.num_layers,1,1)\n",
    "        c0=torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device, dtype=x.dtype)\n",
    "        dec,_=self.decoder(x,(h0,c0)); return self.out(dec)\n",
    "\n",
    "class DenseWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, ctx):\n",
    "        self.features=json.loads(Path(ctx.artifacts[\"features\"]).read_text())[\"features\"]\n",
    "        self.scaler=joblib.load(ctx.artifacts[\"scaler\"])\n",
    "        self.model=torch.jit.load(ctx.artifacts[\"dense_ts\"]); self.model.eval()\n",
    "    def predict(self, ctx, df: pd.DataFrame):\n",
    "        X=df.reindex(columns=self.features, fill_value=0.0).astype(np.float32).values\n",
    "        Xs=self.scaler.transform(X).astype(np.float32)\n",
    "        with torch.no_grad(): x_hat=self.model(torch.from_numpy(Xs)).numpy()\n",
    "        return pd.DataFrame({\"dense_healthscore\": ((Xs-x_hat)**2).mean(axis=1)})\n",
    "\n",
    "class LSTMWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, ctx):\n",
    "        self.features=json.loads(Path(ctx.artifacts[\"features\"]).read_text())[\"features\"]\n",
    "        self.scaler=joblib.load(ctx.artifacts[\"scaler\"])\n",
    "        self.seq_len=int(Path(ctx.artifacts[\"seq_len_txt\"]).read_text())\n",
    "        self.model=torch.jit.load(ctx.artifacts[\"lstm_ts\"]); self.model.eval()\n",
    "    def predict(self, ctx, df: pd.DataFrame):\n",
    "        X=df.reindex(columns=self.features, fill_value=0.0).astype(np.float32).values\n",
    "        Xs=self.scaler.transform(X).astype(np.float32); n,d=Xs.shape; L=self.seq_len\n",
    "        out=np.full((n,), np.nan, np.float32)\n",
    "        if n>=L:\n",
    "            seq=np.stack([Xs[i:i+L] for i in range(n-L+1)], axis=0)\n",
    "            with torch.no_grad(): xh=self.model(torch.from_numpy(seq)).numpy()\n",
    "            err=((seq-xh)**2).mean(axis=2)[:, -1]; out[L-1:]=err\n",
    "        return pd.DataFrame({\"lstm_healthscore\": out})\n",
    "\n",
    "def export_torchscript_dense(in_dim, weights, out_dir):\n",
    "    m=DenseAE(in_dim); m.load_state_dict(torch.load(weights, map_location=\"cpu\")); m.eval()\n",
    "    ex=torch.randn(1,in_dim,dtype=torch.float32); ts=out_dir/\"dense_ae.torchscript.pt\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True); torch.jit.trace(m,ex).save(str(ts)); return ts\n",
    "\n",
    "def export_torchscript_lstm(in_dim, cfg, weights, out_dir, L):\n",
    "    m=LSTMAE(input_dim=in_dim, **cfg); m.load_state_dict(torch.load(weights, map_location=\"cpu\")); m.eval()\n",
    "    ex=torch.randn(1,L,in_dim,dtype=torch.float32); ts=out_dir/\"lstm_ae.torchscript.pt\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True); torch.jit.trace(m,ex).save(str(ts)); return ts\n",
    "\n",
    "def main():\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    features = json.loads((ART_DIR/\"features.json\").read_text())[\"features\"]; in_dim=len(features)\n",
    "    scaler = ART_DIR/\"scaler_prod.pkl\"\n",
    "    for sub in sorted(MODELS_DIR.glob(\"artifact_*\")):\n",
    "        aid=sub.name\n",
    "        dense_pt=sub/\"dense_ae.pt\"; lstm_pt=sub/\"lstm_ae.pt\"\n",
    "        if not dense_pt.exists() or not lstm_pt.exists(): continue\n",
    "        exp=sub/\"export\"; dense_ts=export_torchscript_dense(in_dim, dense_pt, exp)\n",
    "        lstm_ts=export_torchscript_lstm(in_dim, LSTM_CFG[aid], lstm_pt, exp, SEQ_LEN)\n",
    "\n",
    "        # DENSE\n",
    "        with mlflow.start_run(run_name=f\"{aid}-dense\"):\n",
    "            mlflow.set_tags({\"artifact_id\":aid,\"model_type\":\"dense\"})\n",
    "            logged=mlflow.pyfunc.log_model(\n",
    "                artifact_path=\"model\",\n",
    "                python_model=DenseWrapper(),\n",
    "                artifacts={\"features\": str(ART_DIR/\"features.json\"),\n",
    "                           \"scaler\": str(scaler),\n",
    "                           \"dense_ts\": str(dense_ts)},\n",
    "                pip_requirements=[\"mlflow\",\"pandas\",\"numpy\",\"torch\",\"scikit-learn\",\"joblib\"],\n",
    "                registered_model_name=\"signals-anomaly-ae-dense\"\n",
    "            )\n",
    "        # LSTM\n",
    "        with mlflow.start_run(run_name=f\"{aid}-lstm\"):\n",
    "            mlflow.set_tags({\"artifact_id\":aid,\"model_type\":\"lstm\"})\n",
    "            seq_len_txt = mlflow.pyfunc.model._save_artifact(\"seq_len.txt\", data=str(SEQ_LEN).encode())\n",
    "            logged=mlflow.pyfunc.log_model(\n",
    "                artifact_path=\"model\",\n",
    "                python_model=LSTMWrapper(),\n",
    "                artifacts={\"features\": str(ART_DIR/\"features.json\"),\n",
    "                           \"scaler\": str(scaler),\n",
    "                           \"seq_len_txt\": seq_len_txt,\n",
    "                           \"lstm_ts\": str(lstm_ts)},\n",
    "                pip_requirements=[\"mlflow\",\"pandas\",\"numpy\",\"torch\",\"scikit-learn\",\"joblib\"],\n",
    "                registered_model_name=\"signals-anomaly-ae-lstm\"\n",
    "            )\n",
    "    print(\"Registered all artifacts.\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch CUDA (cu121)",
   "language": "python",
   "name": "torchcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
