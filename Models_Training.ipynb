{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f8f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: C:\\ProgramData\\Anaconda3\\envs\\torchcuda\\python.exe\n",
      "Torch ver: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "torch.version.cuda: 12.1\n",
      "GPU: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch, shutil, subprocess, textwrap, sys\n",
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"Torch ver:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44599977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda | AMP: True\n",
      "GPU: NVIDIA GeForce GTX 1650\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, 'Liberation Mono', monospace; max-width: 1000px;\">\n",
       "          <div style=\"margin-bottom:6px;\"><b>Training Dashboard</b> <span style=\"opacity:.7\">| live</span></div>\n",
       "          <div style=\"margin:6px 0;\">\n",
       "            <div>Overall <span style=\"opacity:.7\">(artifact_5 LSTM)</span></div>\n",
       "            <div style=\"height:14px;background:#eee;border-radius:7px;overflow:hidden;\">\n",
       "              <div style=\"height:100%;width:72%;background:#4a90e2;\"></div>\n",
       "            </div>\n",
       "            <div style=\"display:flex;justify-content:space-between;font-size:12px;opacity:.85;\">\n",
       "              <div>291/400 ep</div>\n",
       "              <div>ETA 2:27:00</div>\n",
       "            </div>\n",
       "          </div>\n",
       "          <div style=\"margin:6px 0;\">\n",
       "            <div>Current <span style=\"opacity:.7\">(LSTMAE)</span></div>\n",
       "            <div style=\"height:14px;background:#eee;border-radius:7px;overflow:hidden;\">\n",
       "              <div style=\"height:100%;width:26%;background:#7ed321;\"></div>\n",
       "            </div>\n",
       "            <div style=\"display:flex;justify-content:space-between;font-size:12px;opacity:.85;\">\n",
       "              <div>epoch 12/45</div>\n",
       "              <div>ETA 47:33</div>\n",
       "            </div>\n",
       "          </div>\n",
       "          <div style=\"margin-top:6px;font-size:12px;opacity:.9;\">\n",
       "            <span>汳 23:11:06 </span>\n",
       "            <span style=\"margin-left:8px;\">phase: lstm</span>\n",
       "            <span style=\"margin-left:8px;\">ep: 12</span>\n",
       "            <span style=\"margin-left:8px;\">tr: 1.3224e-04</span>\n",
       "            <span style=\"margin-left:8px;\">va: 1.2723e-04</span>\n",
       "          </div>\n",
       "          <div style=\"margin-top:6px;font-size:12px;opacity:.9;\">\n",
       "            <span><b>GPU</b> util: 88% | mem: 493/4096 MB | name: NVIDIA GeForce GTX 1650</span>\n",
       "          </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Artifacts saved under: C:\\Users\\Ishaan Tiwari\\Desktop\\LSTM_&_DENSE_AE_MODELS\\artifacts_tf\n"
     ]
    }
   ],
   "source": [
    "import os, json, random, shutil, sys, time, threading, math, contextlib, subprocess, platform\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    _NVML_OK = True\n",
    "except Exception:\n",
    "    _NVML_OK = False\n",
    "\n",
    "\n",
    "CSV_FILE = \"synthetic_signal_data.csv\"\n",
    "ARTIFACTS_DIR = Path(\"artifacts_tf\")\n",
    "MODELS_DIR    = Path(\"Models\")\n",
    "FEATURES = [f\"signal_{i}\" for i in range(1, 61)]\n",
    "TIMESTAMP_COL = \"Timestamp\"\n",
    "\n",
    "SEQ_LEN = 30\n",
    "STRIDE  = 1\n",
    "TEST_SIZE = 0.2\n",
    "HEARTBEAT_SECS = 30\n",
    "\n",
    "\n",
    "PARAM_SETS = [\n",
    "    {\"id\":\"artifact_1\",\n",
    "     \"dense\":{\"lr\":1e-3,\"batch\":512,\"epochs\":40,\"patience\":5,\"weight_decay\":0.0},\n",
    "     \"lstm\":{\"lr\":1e-3,\"batch\":128,\"epochs\":40,\"patience\":5,\"hidden\":64,\"latent\":16,\"layers\":1}},\n",
    "    {\"id\":\"artifact_2\",\n",
    "     \"dense\":{\"lr\":5e-4,\"batch\":512,\"epochs\":50,\"patience\":6,\"weight_decay\":1e-5},\n",
    "     \"lstm\":{\"lr\":5e-4,\"batch\":128,\"epochs\":50,\"patience\":6,\"hidden\":96,\"latent\":24,\"layers\":1}},\n",
    "    {\"id\":\"artifact_3\",\n",
    "     \"dense\":{\"lr\":1e-3,\"batch\":1024,\"epochs\":35,\"patience\":5,\"weight_decay\":1e-6},\n",
    "     \"lstm\":{\"lr\":1e-3,\"batch\":256,\"epochs\":35,\"patience\":5,\"hidden\":80,\"latent\":20,\"layers\":1}},\n",
    "    {\"id\":\"artifact_4\",\n",
    "     \"dense\":{\"lr\":2e-3,\"batch\":512,\"epochs\":30,\"patience\":4,\"weight_decay\":0.0},\n",
    "     \"lstm\":{\"lr\":2e-3,\"batch\":128,\"epochs\":30,\"patience\":4,\"hidden\":64,\"latent\":16,\"layers\":2}},\n",
    "    {\"id\":\"artifact_5\",\n",
    "     \"dense\":{\"lr\":7e-4,\"batch\":512,\"epochs\":45,\"patience\":5,\"weight_decay\":5e-6},\n",
    "     \"lstm\":{\"lr\":7e-4,\"batch\":128,\"epochs\":45,\"patience\":5,\"hidden\":72,\"latent\":18,\"layers\":1}},\n",
    "]\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "AMP = (DEVICE.type == \"cuda\")\n",
    "print(\"Using:\", DEVICE, \"| AMP:\", AMP)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    try: print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    except: pass\n",
    "\n",
    "def make_loader(ds,batch,shuffle=True):\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=(DEVICE.type==\"cuda\"),\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "\n",
    "def autocast_ctx():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        return torch.amp.autocast(device_type=\"cuda\", enabled=AMP)\n",
    "    return contextlib.nullcontext()\n",
    "\n",
    "\n",
    "def load_signals_csv(path, features, timestamp_col):\n",
    "    cols = pd.read_csv(path, nrows=0).columns.tolist()\n",
    "    usecols = [c for c in features if c in cols] + ([timestamp_col] if timestamp_col in cols else [])\n",
    "    df = pd.read_csv(path, usecols=usecols)\n",
    "    for f in features:\n",
    "        if f not in df: df[f]=0.0\n",
    "    return df[features].astype(\"float32\").values\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X): self.X = np.asarray(X,dtype=np.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return torch.from_numpy(self.X[idx])\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self,X,seq_len=30,stride=1):\n",
    "        X=np.asarray(X,dtype=np.float32); n=len(X)\n",
    "        if n<seq_len: self.X=np.empty((0,seq_len,X.shape[1]),dtype=np.float32)\n",
    "        else:\n",
    "            num=(n-seq_len)//stride+1\n",
    "            self.X=np.stack([X[i*stride:i*stride+seq_len] for i in range(num)],axis=0)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,idx): return torch.from_numpy(self.X[idx])\n",
    "\n",
    "\n",
    "class DenseAE(nn.Module):\n",
    "    def __init__(self,in_dim=60):\n",
    "        super().__init__()\n",
    "        self.enc=nn.Sequential(nn.Linear(in_dim,40),nn.ReLU(),\n",
    "                               nn.Linear(40,20),nn.ReLU(),\n",
    "                               nn.Linear(20,10),nn.ReLU())\n",
    "        self.dec=nn.Sequential(nn.Linear(10,20),nn.ReLU(),\n",
    "                               nn.Linear(20,40),nn.ReLU(),\n",
    "                               nn.Linear(40,in_dim))\n",
    "    def forward(self,x): return self.dec(self.enc(x))\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self,input_dim=60,hidden_dim=64,latent_dim=16,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder=nn.LSTM(input_dim,hidden_dim,num_layers=num_layers,batch_first=True)\n",
    "        self.to_latent=nn.Linear(hidden_dim,latent_dim)\n",
    "        self.from_latent=nn.Linear(latent_dim,hidden_dim)\n",
    "        self.decoder=nn.LSTM(input_dim,hidden_dim,num_layers=num_layers,batch_first=True)\n",
    "        self.out=nn.Linear(hidden_dim,input_dim)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "    def forward(self,x):\n",
    "        enc_out,_=self.encoder(x); h_last=enc_out[:,-1,:]\n",
    "        z=self.to_latent(h_last); base=self.from_latent(z)\n",
    "        h0=base.unsqueeze(0).repeat(self.num_layers,1,1)\n",
    "        c0=torch.zeros(self.num_layers, x.size(0), self.hidden_dim, device=x.device, dtype=x.dtype)\n",
    "        dec_out,_=self.decoder(x,(h0,c0))\n",
    "        return self.out(dec_out)\n",
    "\n",
    "\n",
    "def _fmt_eta(seconds):\n",
    "    if seconds is None or math.isinf(seconds) or seconds < 0: return \"窶能"\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:d}:{m:02d}:{s:02d}\" if h else f\"{m:02d}:{s:02d}\"\n",
    "\n",
    "class LiveBoard:\n",
    "    def __init__(self):\n",
    "        self.html_tpl = \"\"\"\n",
    "        <div style=\"font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, 'Liberation Mono', monospace; max-width: 1000px;\">\n",
    "          <div style=\"margin-bottom:6px;\"><b>Training Dashboard</b> <span style=\"opacity:.7\">| live</span></div>\n",
    "          <div style=\"margin:6px 0;\">\n",
    "            <div>Overall <span style=\"opacity:.7\">({overall_desc})</span></div>\n",
    "            <div style=\"height:14px;background:#eee;border-radius:7px;overflow:hidden;\">\n",
    "              <div style=\"height:100%;width:{overall_pct}%;background:#4a90e2;\"></div>\n",
    "            </div>\n",
    "            <div style=\"display:flex;justify-content:space-between;font-size:12px;opacity:.85;\">\n",
    "              <div>{overall_n}/{overall_total} ep</div>\n",
    "              <div>ETA {_overall_eta}</div>\n",
    "            </div>\n",
    "          </div>\n",
    "          <div style=\"margin:6px 0;\">\n",
    "            <div>Current <span style=\"opacity:.7\">({current_desc})</span></div>\n",
    "            <div style=\"height:14px;background:#eee;border-radius:7px;overflow:hidden;\">\n",
    "              <div style=\"height:100%;width:{current_pct}%;background:#7ed321;\"></div>\n",
    "            </div>\n",
    "            <div style=\"display:flex;justify-content:space-between;font-size:12px;opacity:.85;\">\n",
    "              <div>epoch {current_n}/{current_total}</div>\n",
    "              <div>ETA {_current_eta}</div>\n",
    "            </div>\n",
    "          </div>\n",
    "          <div style=\"margin-top:6px;font-size:12px;opacity:.9;\">\n",
    "            <span>汳 {heartbeat} </span>\n",
    "            <span style=\"margin-left:8px;\">phase: {phase}</span>\n",
    "            <span style=\"margin-left:8px;\">ep: {epoch}</span>\n",
    "            <span style=\"margin-left:8px;\">tr: {last_tr}</span>\n",
    "            <span style=\"margin-left:8px;\">va: {last_va}</span>\n",
    "          </div>\n",
    "          <div style=\"margin-top:6px;font-size:12px;opacity:.9;\">\n",
    "            <span><b>GPU</b> util: {gpu_util} | mem: {gpu_mem_used}/{gpu_mem_total} MB | name: {gpu_name}</span>\n",
    "          </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        self.state = {\n",
    "            \"overall_desc\":\"窶能", \"overall_n\":0, \"overall_total\":1, \"overall_eta\":None,\n",
    "            \"current_desc\":\"窶能", \"current_n\":0, \"current_total\":1, \"current_eta\":None,\n",
    "            \"heartbeat\":\"窶能", \"phase\":\"init\", \"epoch\":0, \"last_tr\":\"窶能", \"last_va\":\"窶能",\n",
    "            \"gpu_util\":\"窶能", \"gpu_mem_used\":\"窶能", \"gpu_mem_total\":\"窶能", \"gpu_name\":\"窶能"\n",
    "        }\n",
    "        self._display = display(HTML(self._render()), display_id=True)\n",
    "\n",
    "    def _render(self):\n",
    "        s = self.state\n",
    "        return self.html_tpl.format(\n",
    "            overall_desc=s[\"overall_desc\"],\n",
    "            overall_pct=0 if s[\"overall_total\"]==0 else int(100*s[\"overall_n\"]/max(1,s[\"overall_total\"])),\n",
    "            overall_n=s[\"overall_n\"], overall_total=s[\"overall_total\"],\n",
    "            _overall_eta=_fmt_eta(s[\"overall_eta\"]),\n",
    "            current_desc=s[\"current_desc\"],\n",
    "            current_pct=0 if s[\"current_total\"]==0 else int(100*s[\"current_n\"]/max(1,s[\"current_total\"])),\n",
    "            current_n=s[\"current_n\"], current_total=s[\"current_total\"],\n",
    "            _current_eta=_fmt_eta(s[\"current_eta\"]),\n",
    "            heartbeat=s[\"heartbeat\"], phase=s[\"phase\"], epoch=s[\"epoch\"],\n",
    "            last_tr=s[\"last_tr\"], last_va=s[\"last_va\"],\n",
    "            gpu_util=s[\"gpu_util\"], gpu_mem_used=s[\"gpu_mem_used\"],\n",
    "            gpu_mem_total=s[\"gpu_mem_total\"], gpu_name=s[\"gpu_name\"]\n",
    "        )\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        self.state.update(kwargs)\n",
    "        self._display.update(HTML(self._render()))\n",
    "\n",
    "\n",
    "class Heartbeat:\n",
    "    def __init__(self, interval, board: LiveBoard):\n",
    "        self.interval = max(5, int(interval))\n",
    "        self._stop=False\n",
    "        self.board = board\n",
    "        self._gpu_name = \"窶能"\n",
    "        if DEVICE.type == \"cuda\":\n",
    "            try:\n",
    "                self._gpu_name = torch.cuda.get_device_name(0)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    def _gpu_stats(self):\n",
    "        if DEVICE.type != \"cuda\" or not _NVML_OK:\n",
    "            return (\"窶能", \"窶能", \"窶能")\n",
    "        try:\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "            util = pynvml.nvmlDeviceGetUtilizationRates(handle).gpu  # %\n",
    "            mem = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            used = int(mem.used / 1024**2)\n",
    "            total = int(mem.total / 1024**2)\n",
    "            return (f\"{util}%\", str(used), str(total))\n",
    "        except Exception:\n",
    "            return (\"窶能", \"窶能", \"窶能")\n",
    "\n",
    "    def start(self):\n",
    "        def loop():\n",
    "            while not self._stop:\n",
    "                time.sleep(self.interval)\n",
    "                if self._stop: break\n",
    "                util, used, total = self._gpu_stats()\n",
    "                self.board.update(\n",
    "                    heartbeat=time.strftime(\"%H:%M:%S\"),\n",
    "                    gpu_util=util, gpu_mem_used=used, gpu_mem_total=total, gpu_name=self._gpu_name\n",
    "                )\n",
    "        self.thr = threading.Thread(target=loop, daemon=True); self.thr.start()\n",
    "    def stop(self): self._stop=True\n",
    "\n",
    "class ETA:\n",
    "    def __init__(self, total, alpha=0.2):\n",
    "        self.total = max(1,int(total))\n",
    "        self.done = 0\n",
    "        self.alpha = alpha\n",
    "        self._last = time.time()\n",
    "        self.sec_per_unit = None\n",
    "    def step(self, n=1):\n",
    "        now = time.time()\n",
    "        dt = now - self._last; self._last = now\n",
    "        if dt <= 0: return\n",
    "        spu = dt / max(1,n)\n",
    "        if self.sec_per_unit is None: self.sec_per_unit = spu\n",
    "        else: self.sec_per_unit = self.alpha*spu + (1-self.alpha)*self.sec_per_unit\n",
    "        self.done += n\n",
    "    def remaining(self):\n",
    "        left = max(0, self.total - self.done)\n",
    "        if self.sec_per_unit is None: return None\n",
    "        return left * self.sec_per_unit\n",
    "\n",
    "\n",
    "def _train_epoch_tabular(model, opt, crit, loader):\n",
    "    model.train(); tot=0; n=0\n",
    "    for xb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with autocast_ctx():\n",
    "            loss = crit(model(xb), xb)\n",
    "        loss.backward(); opt.step()\n",
    "        bs = xb.size(0); tot += loss.item()*bs; n += bs\n",
    "    return tot/max(1,n)\n",
    "\n",
    "def _eval_tabular(model, crit, loader):\n",
    "    model.eval(); tot=0; n=0\n",
    "    with torch.no_grad():\n",
    "        for xb in loader:\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            with autocast_ctx():\n",
    "                loss = crit(model(xb), xb)\n",
    "            bs = xb.size(0); tot += loss.item()*bs; n += bs\n",
    "    return tot/max(1,n)\n",
    "\n",
    "def _train_epoch_seq(model, opt, crit, loader):\n",
    "    model.train(); tot=0; n=0\n",
    "    for xb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with autocast_ctx():\n",
    "            loss = crit(model(xb), xb)\n",
    "        loss.backward(); opt.step()\n",
    "        bs = xb.size(0); tot += loss.item()*bs; n += bs\n",
    "    return tot/max(1,n)\n",
    "\n",
    "def _eval_seq(model, crit, loader):\n",
    "    model.eval(); tot=0; n=0\n",
    "    with torch.no_grad():\n",
    "        for xb in loader:\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            with autocast_ctx():\n",
    "                loss = crit(model(xb), xb)\n",
    "            bs = xb.size(0); tot += loss.item()*bs; n += bs\n",
    "    return tot/max(1,n)\n",
    "\n",
    "\n",
    "def train_dense(params,Xtr,Xval,board,overall_eta,hb=None):\n",
    "    model=DenseAE(Xtr.shape[1]).to(DEVICE)\n",
    "    opt=torch.optim.AdamW(model.parameters(),lr=params[\"lr\"],weight_decay=params.get(\"weight_decay\",0.0))\n",
    "    crit=nn.MSELoss()\n",
    "    tr_loader=make_loader(TabularDataset(Xtr),params[\"batch\"],True)\n",
    "    va_loader=make_loader(TabularDataset(Xval),params[\"batch\"],False)\n",
    "\n",
    "    epochs=int(params.get(\"epochs\",10)); patience=int(params.get(\"patience\",5)); no_imp=0\n",
    "    cur_eta = ETA(total=epochs)\n",
    "    best=float(\"inf\"); best_state=None\n",
    "\n",
    "    board.update(current_desc=\"DenseAE\", current_n=0, current_total=epochs, last_tr=\"窶能", last_va=\"窶能")\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr = _train_epoch_tabular(model,opt,crit,tr_loader)\n",
    "        va = _eval_tabular(model,crit,va_loader)\n",
    "        if hb: board.update(phase=\"dense\", epoch=ep)\n",
    "\n",
    "        cur_eta.step(1); overall_eta.step(1)\n",
    "        board.update(current_n=ep, current_eta=cur_eta.remaining(),\n",
    "                     overall_n=overall_eta.done, overall_eta=overall_eta.remaining(),\n",
    "                     last_tr=f\"{tr:.4e}\", last_va=f\"{va:.4e}\")\n",
    "\n",
    "        if va < best - 1e-12:\n",
    "            best = va; best_state = model.state_dict()\n",
    "            no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "            if no_imp >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, float(best)\n",
    "\n",
    "def train_lstm(params,Xtr,Xval,seq_len,stride,board,overall_eta,hb=None):\n",
    "    model=LSTMAE(input_dim=Xtr.shape[1], hidden_dim=int(params.get(\"hidden\",64)),\n",
    "                 latent_dim=int(params.get(\"latent\",16)), num_layers=int(params.get(\"layers\",1))).to(DEVICE)\n",
    "    opt=torch.optim.AdamW(model.parameters(),lr=params[\"lr\"])\n",
    "    crit=nn.MSELoss()\n",
    "    tr_loader=make_loader(SequenceDataset(Xtr,seq_len,stride),params[\"batch\"],True)\n",
    "    va_loader=make_loader(SequenceDataset(Xval,seq_len,stride),params[\"batch\"],False)\n",
    "\n",
    "    epochs=int(params.get(\"epochs\",10)); patience=int(params.get(\"patience\",5)); no_imp=0\n",
    "    cur_eta = ETA(total=epochs)\n",
    "    best=float(\"inf\"); best_state=None\n",
    "\n",
    "    board.update(current_desc=\"LSTMAE\", current_n=0, current_total=epochs, last_tr=\"窶能", last_va=\"窶能")\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr = _train_epoch_seq(model,opt,crit,tr_loader)\n",
    "        va = _eval_seq(model,crit,va_loader)\n",
    "        if hb: board.update(phase=\"lstm\", epoch=ep)\n",
    "\n",
    "        cur_eta.step(1); overall_eta.step(1)\n",
    "        board.update(current_n=ep, current_eta=cur_eta.remaining(),\n",
    "                     overall_n=overall_eta.done, overall_eta=overall_eta.remaining(),\n",
    "                     last_tr=f\"{tr:.4e}\", last_va=f\"{va:.4e}\")\n",
    "\n",
    "        if va < best - 1e-12:\n",
    "            best = va; best_state = model.state_dict()\n",
    "            no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "            if no_imp >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, float(best)\n",
    "\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True); MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "planned_epochs = sum(int(c[\"dense\"].get(\"epochs\",0)) + int(c[\"lstm\"].get(\"epochs\",0)) for c in PARAM_SETS)\n",
    "board = LiveBoard()\n",
    "board.update(overall_desc=\"init\", overall_n=0, overall_total=planned_epochs, current_desc=\"窶能", current_n=0, current_total=1)\n",
    "\n",
    "hb = Heartbeat(HEARTBEAT_SECS, board); hb.start()\n",
    "overall_eta = ETA(total=planned_epochs)\n",
    "\n",
    "artifacts_index=[]\n",
    "try:\n",
    "    X = load_signals_csv(CSV_FILE, FEATURES, TIMESTAMP_COL)\n",
    "    (ARTIFACTS_DIR / \"features.json\").write_text(json.dumps({\"timestamp_col\": TIMESTAMP_COL, \"features\": FEATURES}, indent=2))\n",
    "    try:\n",
    "        schema = pd.read_csv(CSV_FILE, nrows=0).dtypes.apply(lambda t: str(t)).to_dict()\n",
    "        (ARTIFACTS_DIR / \"schema.json\").write_text(json.dumps(schema, indent=2))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    Xtr, Xval = train_test_split(X, test_size=TEST_SIZE, random_state=SEED, shuffle=True)\n",
    "    scaler = MinMaxScaler(); Xtr = scaler.fit_transform(Xtr); Xval = scaler.transform(Xval)\n",
    "    joblib.dump(scaler, ARTIFACTS_DIR/\"scaler_prod.pkl\")\n",
    "\n",
    "    if not (ARTIFACTS_DIR/\"thresholds.json\").exists():\n",
    "        (ARTIFACTS_DIR/\"thresholds.json\").write_text(json.dumps({\n",
    "            \"dense\": {\"method\": \"percentile\", \"value\": 0.99},\n",
    "            \"lstm\":  {\"method\": \"percentile\", \"value\": 0.99, \"aggregate\": \"last\"}\n",
    "        }, indent=2))\n",
    "\n",
    "    try:\n",
    "        env_txt = subprocess.run([sys.executable, \"-m\", \"pip\", \"freeze\"], capture_output=True, text=True).stdout\n",
    "        (ARTIFACTS_DIR / \"env.txt\").write_text(env_txt)\n",
    "    except Exception:\n",
    "        pass\n",
    "    system = {\n",
    "        \"python\": sys.version,\n",
    "        \"torch\": torch.__version__,\n",
    "        \"cuda_is_available\": torch.cuda.is_available(),\n",
    "        \"cuda_version\": torch.version.cuda if hasattr(torch.version, \"cuda\") else None,\n",
    "        \"cudnn_version\": torch.backends.cudnn.version(),\n",
    "        \"device\": (torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\"),\n",
    "        \"os\": platform.platform(),\n",
    "    }\n",
    "    (ARTIFACTS_DIR / \"system.json\").write_text(json.dumps(system, indent=2))\n",
    "\n",
    "    for cfg in PARAM_SETS:\n",
    "        art_id = cfg.get(\"id\",\"artifact\")\n",
    "        out_dir = MODELS_DIR / art_id\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        board.update(overall_desc=f\"{art_id} Dense\", phase=f\"{art_id}/dense\", epoch=0)\n",
    "        dense_model, dense_val = train_dense(cfg[\"dense\"], Xtr, Xval, board, overall_eta, hb=hb)\n",
    "        torch.save(dense_model.state_dict(), out_dir/\"dense_ae.pt\")\n",
    "\n",
    "        board.update(overall_desc=f\"{art_id} LSTM\", phase=f\"{art_id}/lstm\", epoch=0)\n",
    "        lstm_model, lstm_val = train_lstm(cfg[\"lstm\"], Xtr, Xval, SEQ_LEN, STRIDE, board, overall_eta, hb=hb)\n",
    "        torch.save(lstm_model.state_dict(), out_dir/\"lstm_ae.pt\")\n",
    "\n",
    "        manifest = {\n",
    "            \"id\": art_id,\n",
    "            \"input_dim\": len(FEATURES),\n",
    "            \"features\": FEATURES,\n",
    "            \"seq_len\": int(SEQ_LEN),\n",
    "            \"stride\": int(STRIDE),\n",
    "            \"aggregate\": \"last\",\n",
    "            \"dense\": {\n",
    "                \"val_loss\": float(dense_val),\n",
    "                \"batch\": int(cfg[\"dense\"][\"batch\"]),\n",
    "                \"weight_decay\": float(cfg[\"dense\"].get(\"weight_decay\", 0.0)),\n",
    "                \"lr\": float(cfg[\"dense\"][\"lr\"]),\n",
    "                \"epochs_planned\": int(cfg[\"dense\"][\"epochs\"]),\n",
    "                \"patience\": int(cfg[\"dense\"][\"patience\"])\n",
    "            },\n",
    "            \"lstm\": {\n",
    "                \"val_loss\": float(lstm_val),\n",
    "                \"hidden\": int(cfg[\"lstm\"][\"hidden\"]),\n",
    "                \"latent\": int(cfg[\"lstm\"][\"latent\"]),\n",
    "                \"layers\": int(cfg[\"lstm\"][\"layers\"]),\n",
    "                \"batch\": int(cfg[\"lstm\"][\"batch\"]),\n",
    "                \"lr\": float(cfg[\"lstm\"][\"lr\"]),\n",
    "                \"epochs_planned\": int(cfg[\"lstm\"][\"epochs\"]),\n",
    "                \"patience\": int(cfg[\"lstm\"][\"patience\"])\n",
    "            },\n",
    "            \"seed\": int(SEED),\n",
    "            \"test_size\": float(TEST_SIZE)\n",
    "        }\n",
    "        (out_dir / \"manifest.json\").write_text(json.dumps(manifest, indent=2))\n",
    "\n",
    "        trainlog = {\n",
    "            \"dense\": {\"val_best\": float(dense_val)},\n",
    "            \"lstm\":  {\"val_best\": float(lstm_val)},\n",
    "            \"epochs_planned\": int(cfg[\"dense\"][\"epochs\"]) + int(cfg[\"lstm\"][\"epochs\"]),\n",
    "            \"finished_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        (out_dir / \"training_report.json\").write_text(json.dumps(trainlog, indent=2))\n",
    "\n",
    "        artifacts_index.append({\"id\": art_id, \"dense_val\": float(dense_val), \"lstm_val\": float(lstm_val)})\n",
    "\n",
    "    if artifacts_index:\n",
    "        best = sorted(artifacts_index, key=lambda r: 0.5*r[\"dense_val\"] + 0.5*r[\"lstm_val\"])[0][\"id\"]\n",
    "        (ARTIFACTS_DIR/\"registry.json\").write_text(json.dumps({\"production_artifact\": best}, indent=2))\n",
    "\n",
    "finally:\n",
    "    hb.stop()\n",
    "\n",
    "print(\"Training finished. Artifacts saved under:\", ARTIFACTS_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ac18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch CUDA (cu121)",
   "language": "python",
   "name": "torchcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
